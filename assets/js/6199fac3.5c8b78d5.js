"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[723],{8453(e,n,t){t.d(n,{R:()=>o,x:()=>a});var i=t(6540);const s={},r=i.createContext(s);function o(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(r.Provider,{value:n},e.children)}},9446(e,n,t){t.r(n),t.d(n,{assets:()=>M,contentTitle:()=>D,default:()=>L,frontMatter:()=>R,metadata:()=>i,toc:()=>N});const i=JSON.parse('{"id":"module-1-intro/what-is-physical-ai","title":"What is Physical AI?","description":"Introduction to Physical AI and embodied intelligence","source":"@site/docs/module-1-intro/01-what-is-physical-ai.mdx","sourceDirName":"module-1-intro","slug":"/module-1-intro/what-is-physical-ai","permalink":"/physical-ai-textbook-speckit/docs/module-1-intro/what-is-physical-ai","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"What is Physical AI?","description":"Introduction to Physical AI and embodied intelligence","keywords":["physical-ai","embodied-intelligence","robotics","ai"],"week":1,"estimated_time":45,"difficulty":"beginner","learning_objectives":["Define Physical AI and explain how it differs from traditional AI","Describe the key challenges of embodied intelligence","Identify the core components of a Physical AI system","Explain why humanoid robots are gaining importance in AI research"],"prerequisites":[]},"sidebar":"tutorialSidebar","previous":{"title":"Welcome to Physical AI","permalink":"/physical-ai-textbook-speckit/docs/"},"next":{"title":"Sensor Systems","permalink":"/physical-ai-textbook-speckit/docs/module-1-intro/sensor-systems"}}');var s=t(4848),r=t(8453),o=t(6540),a=t(4164),l=t(7559),c=t(3104),d=t(6347),h=t(205),u=t(7485),p=t(1682),m=t(679);function x(e){return o.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,o.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function f(e){const{values:n,children:t}=e;return(0,o.useMemo)(()=>{const e=n??function(e){return x(e).map(({props:{value:e,label:n,attributes:t,default:i}})=>({value:e,label:n,attributes:t,default:i}))}(t);return function(e){const n=(0,p.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,t])}function g({value:e,tabValues:n}){return n.some(n=>n.value===e)}function b({queryString:e=!1,groupId:n}){const t=(0,d.W6)(),i=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,u.aZ)(i),(0,o.useCallback)(e=>{if(!i)return;const n=new URLSearchParams(t.location.search);n.set(i,e),t.replace({...t.location,search:n.toString()})},[i,t])]}function y(e){const{defaultValue:n,queryString:t=!1,groupId:i}=e,s=f(e),[r,a]=(0,o.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!g({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find(e=>e.default)??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:s})),[l,c]=b({queryString:t,groupId:i}),[d,u]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,i]=(0,m.Dv)(n);return[t,(0,o.useCallback)(e=>{n&&i.set(e)},[n,i])]}({groupId:i}),p=(()=>{const e=l??d;return g({value:e,tabValues:s})?e:null})();(0,h.A)(()=>{p&&a(p)},[p]);return{selectedValue:r,selectValue:(0,o.useCallback)(e=>{if(!g({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);a(e),c(e),u(e)},[c,u,s]),tabValues:s}}var j=t(2303);const v="tabList__CuJ",w="tabItem_LNqP";function I({className:e,block:n,selectedValue:t,selectValue:i,tabValues:r}){const o=[],{blockElementScrollPositionUntilNextRender:l}=(0,c.a_)(),d=e=>{const n=e.currentTarget,s=o.indexOf(n),a=r[s].value;a!==t&&(l(n),i(a))},h=e=>{let n=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const t=o.indexOf(e.currentTarget)+1;n=o[t]??o[0];break}case"ArrowLeft":{const t=o.indexOf(e.currentTarget)-1;n=o[t]??o[o.length-1];break}}n?.focus()};return(0,s.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,a.A)("tabs",{"tabs--block":n},e),children:r.map(({value:e,label:n,attributes:i})=>(0,s.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{o.push(e)},onKeyDown:h,onClick:d,...i,className:(0,a.A)("tabs__item",w,i?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function k({lazy:e,children:n,selectedValue:t}){const i=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=i.find(e=>e.props.value===t);return e?(0,o.cloneElement)(e,{className:(0,a.A)("margin-top--md",e.props.className)}):null}return(0,s.jsx)("div",{className:"margin-top--md",children:i.map((e,n)=>(0,o.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function A(e){const n=y(e);return(0,s.jsxs)("div",{className:(0,a.A)(l.G.tabs.container,"tabs-container",v),children:[(0,s.jsx)(I,{...n,...e}),(0,s.jsx)(k,{...n,...e})]})}function P(e){const n=(0,j.A)();return(0,s.jsx)(A,{...e,children:x(e.children)},String(n))}const T="tabItem_Ymn6";function _({children:e,hidden:n,className:t}){return(0,s.jsx)("div",{role:"tabpanel",className:(0,a.A)(T,t),hidden:n,children:e})}const C={beginner:{label:"Beginner",color:"var(--ifm-color-success-darkest)",bgColor:"var(--ifm-color-success-lightest)"},intermediate:{label:"Intermediate",color:"var(--ifm-color-warning-darkest)",bgColor:"var(--ifm-color-warning-lightest)"},advanced:{label:"Advanced",color:"var(--ifm-color-danger-darkest)",bgColor:"var(--ifm-color-danger-lightest)"}};function E({level:e}){const n=C[e]||C.beginner;return(0,s.jsx)("span",{style:{display:"inline-flex",alignItems:"center",padding:"4px 10px",borderRadius:"12px",fontSize:"12px",fontWeight:600,color:n.color,backgroundColor:n.bgColor,textTransform:"uppercase",letterSpacing:"0.5px"},children:n.label})}function S({title:e,difficulty:n,estimatedTime:t,children:i,hint:r,type:a="conceptual"}){const[l,c]=(0,o.useState)(!1);return(0,s.jsxs)("div",{style:{margin:"24px 0",padding:"20px",border:"1px solid var(--ifm-color-emphasis-300)",borderRadius:"8px",backgroundColor:"var(--ifm-background-surface-color)"},children:[(0,s.jsxs)("div",{style:{display:"flex",flexWrap:"wrap",alignItems:"center",gap:"12px",marginBottom:"16px",paddingBottom:"12px",borderBottom:"1px solid var(--ifm-color-emphasis-200)"},children:[(0,s.jsx)("span",{style:{fontSize:"11px",color:"var(--ifm-color-emphasis-600)",textTransform:"uppercase",letterSpacing:"0.5px",fontWeight:600},children:{coding:"Coding Exercise",conceptual:"Conceptual Exercise","hands-on":"Hands-on Lab"}[a]}),(0,s.jsx)(E,{level:n}),t&&(0,s.jsxs)("span",{style:{display:"inline-flex",alignItems:"center",gap:"4px",fontSize:"12px",color:"var(--ifm-color-emphasis-600)"},children:[(0,s.jsxs)("svg",{width:"14",height:"14",viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:"2",children:[(0,s.jsx)("circle",{cx:"12",cy:"12",r:"10"}),(0,s.jsx)("polyline",{points:"12 6 12 12 16 14"})]}),"~",t," min"]})]}),(0,s.jsx)("h4",{style:{margin:"0 0 12px",fontSize:"18px",fontWeight:600,color:"var(--ifm-heading-color)"},children:e}),(0,s.jsx)("div",{style:{fontSize:"15px",lineHeight:"1.6",color:"var(--ifm-font-color-base)"},children:i}),r&&(0,s.jsxs)("div",{style:{marginTop:"16px"},children:[(0,s.jsxs)("button",{onClick:()=>c(!l),style:{display:"inline-flex",alignItems:"center",gap:"6px",padding:"8px 12px",background:"transparent",border:"1px solid var(--ifm-color-emphasis-300)",borderRadius:"6px",cursor:"pointer",fontSize:"13px",color:"var(--ifm-color-primary)",fontFamily:"inherit"},children:[(0,s.jsxs)("svg",{width:"16",height:"16",viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:"2",children:[(0,s.jsx)("circle",{cx:"12",cy:"12",r:"10"}),(0,s.jsx)("path",{d:"M9.09 9a3 3 0 0 1 5.83 1c0 2-3 3-3 3"}),(0,s.jsx)("line",{x1:"12",y1:"17",x2:"12.01",y2:"17"})]}),l?"Hide Hint":"Show Hint"]}),l&&(0,s.jsxs)("div",{style:{marginTop:"12px",padding:"12px 16px",background:"var(--ifm-color-primary-lightest)",borderRadius:"6px",borderLeft:"3px solid var(--ifm-color-primary)",fontSize:"14px",color:"var(--ifm-color-emphasis-800)"},children:[(0,s.jsx)("strong",{style:{display:"block",marginBottom:"4px"},children:"Hint:"}),r]})]})]})}const R={sidebar_position:1,title:"What is Physical AI?",description:"Introduction to Physical AI and embodied intelligence",keywords:["physical-ai","embodied-intelligence","robotics","ai"],week:1,estimated_time:45,difficulty:"beginner",learning_objectives:["Define Physical AI and explain how it differs from traditional AI","Describe the key challenges of embodied intelligence","Identify the core components of a Physical AI system","Explain why humanoid robots are gaining importance in AI research"],prerequisites:[]},D="What is Physical AI?",M={},N=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction",id:"introduction",level:2},{value:"The Evolution from Digital to Physical AI",id:"the-evolution-from-digital-to-physical-ai",level:2},{value:"Core Components of Physical AI",id:"core-components-of-physical-ai",level:2},{value:"1. Perception",id:"1-perception",level:3},{value:"2. World Model",id:"2-world-model",level:3},{value:"3. Planning and Decision Making",id:"3-planning-and-decision-making",level:3},{value:"The Embodiment Hypothesis",id:"the-embodiment-hypothesis",level:2},{value:"Why Humanoid Robots?",id:"why-humanoid-robots",level:2},{value:"Summary",id:"summary",level:2},{value:"What&#39;s Next?",id:"whats-next",level:2},{value:"Exercises",id:"exercises",level:2}];function W(e){const n={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"what-is-physical-ai",children:"What is Physical AI?"})}),"\n","\n",(0,s.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Define Physical AI and explain how it differs from traditional AI"}),"\n",(0,s.jsx)(n.li,{children:"Describe the key challenges of embodied intelligence"}),"\n",(0,s.jsx)(n.li,{children:"Identify the core components of a Physical AI system"}),"\n",(0,s.jsx)(n.li,{children:"Explain why humanoid robots are gaining importance in AI research"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Physical AI"})," refers to artificial intelligence systems that interact with the physical world through sensors and actuators. Unlike purely digital AI that processes data in a virtual environment, Physical AI must navigate the complexities of real-world physics, uncertainty, and real-time constraints."]}),"\n",(0,s.jsx)(n.admonition,{title:"Key Insight",type:"info",children:(0,s.jsx)(n.p,{children:"Physical AI is not just about building smart robots\u2014it's about creating intelligent systems that can perceive, reason, and act in the physical world safely and effectively."})}),"\n",(0,s.jsx)(n.h2,{id:"the-evolution-from-digital-to-physical-ai",children:"The Evolution from Digital to Physical AI"}),"\n",(0,s.jsx)(n.p,{children:"Traditional AI systems, like language models or image classifiers, operate in well-defined digital environments:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Input"}),": Structured data (text, images, numbers)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Processing"}),": Computation on servers"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Output"}),": Predictions, classifications, generated content"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Physical AI systems face additional challenges:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Input"}),": Noisy sensor data from cameras, LiDAR, IMUs"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Processing"}),": Real-time computation with strict latency requirements"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Output"}),": Physical actions that must be safe and precise"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"core-components-of-physical-ai",children:"Core Components of Physical AI"}),"\n",(0,s.jsx)(n.p,{children:"A typical Physical AI system consists of several interconnected components:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     Physical AI System                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Sensors  \u2502 -> \u2502  Perception   \u2502 -> \u2502 World Model      \u2502  \u2502\n\u2502  \u2502          \u2502    \u2502  (Computer    \u2502    \u2502 (Scene Graph,    \u2502  \u2502\n\u2502  \u2502 - Camera \u2502    \u2502   Vision,     \u2502    \u2502  Semantic Map)   \u2502  \u2502\n\u2502  \u2502 - LiDAR  \u2502    \u2502   3D Recon)   \u2502    \u2502                  \u2502  \u2502\n\u2502  \u2502 - IMU    \u2502    \u2502               \u2502    \u2502                  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                 \u2502            \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502Actuators \u2502 <- \u2502  Control      \u2502 <- \u2502 Planning &       \u2502  \u2502\n\u2502  \u2502          \u2502    \u2502  (Motor       \u2502    \u2502 Decision Making  \u2502  \u2502\n\u2502  \u2502 - Motors \u2502    \u2502   Commands,   \u2502    \u2502 (Task Planning,  \u2502  \u2502\n\u2502  \u2502 - Joints \u2502    \u2502   PID)        \u2502    \u2502  Path Planning)  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,s.jsx)(n.h3,{id:"1-perception",children:"1. Perception"}),"\n",(0,s.jsx)(n.p,{children:"The perception layer converts raw sensor data into meaningful representations:"}),"\n",(0,s.jsxs)(P,{children:[(0,s.jsxs)(_,{value:"camera",label:"Camera",default:!0,children:[(0,s.jsx)(n.p,{children:"Cameras provide rich visual information for object detection, scene understanding, and visual SLAM."}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import cv2\nimport numpy as np\n\ndef process_camera_frame(frame: np.ndarray) -> dict:\n    """Process a camera frame for object detection."""\n    # Convert to RGB for neural network input\n    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\n    # Normalize pixel values\n    normalized = rgb_frame.astype(np.float32) / 255.0\n\n    return {\n        "rgb": normalized,\n        "shape": frame.shape,\n        "timestamp": time.time()\n    }\n'})})]}),(0,s.jsxs)(_,{value:"lidar",label:"LiDAR",children:[(0,s.jsx)(n.p,{children:"LiDAR sensors provide precise 3D distance measurements for mapping and obstacle detection."}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import numpy as np\n\ndef process_lidar_scan(points: np.ndarray) -> dict:\n    """Process LiDAR point cloud data."""\n    # points shape: (N, 3) for x, y, z coordinates\n\n    # Filter ground plane (simple threshold)\n    non_ground = points[points[:, 2] > 0.1]\n\n    # Calculate distance from sensor\n    distances = np.linalg.norm(non_ground, axis=1)\n\n    return {\n        "points": non_ground,\n        "min_distance": distances.min(),\n        "max_distance": distances.max()\n    }\n'})})]}),(0,s.jsxs)(_,{value:"imu",label:"IMU",children:[(0,s.jsx)(n.p,{children:"Inertial Measurement Units track orientation and acceleration for balance and motion estimation."}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from dataclasses import dataclass\n\n@dataclass\nclass IMUReading:\n    """IMU sensor reading."""\n    accelerometer: tuple[float, float, float]  # m/s\xb2\n    gyroscope: tuple[float, float, float]      # rad/s\n    magnetometer: tuple[float, float, float]   # \u03bcT\n    timestamp: float\n\ndef estimate_orientation(imu: IMUReading) -> tuple:\n    """Estimate roll and pitch from accelerometer."""\n    ax, ay, az = imu.accelerometer\n\n    roll = np.arctan2(ay, az)\n    pitch = np.arctan2(-ax, np.sqrt(ay**2 + az**2))\n\n    return roll, pitch\n'})})]})]}),"\n",(0,s.jsx)(n.h3,{id:"2-world-model",children:"2. World Model"}),"\n",(0,s.jsx)(n.p,{children:"The world model maintains a representation of the environment:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from dataclasses import dataclass, field\nfrom typing import Dict, List\n\n@dataclass\nclass WorldObject:\n    """Represents an object in the world model."""\n    id: str\n    class_name: str\n    position: tuple[float, float, float]\n    orientation: tuple[float, float, float, float]  # quaternion\n    confidence: float\n    last_seen: float\n\n@dataclass\nclass WorldModel:\n    """Maintains the robot\'s understanding of its environment."""\n    objects: Dict[str, WorldObject] = field(default_factory=dict)\n    robot_pose: tuple = (0.0, 0.0, 0.0, 0.0, 0.0, 0.0)  # x, y, z, roll, pitch, yaw\n\n    def update_object(self, obj: WorldObject) -> None:\n        """Update or add an object to the world model."""\n        self.objects[obj.id] = obj\n\n    def get_nearby_objects(self, radius: float) -> List[WorldObject]:\n        """Get objects within a certain radius of the robot."""\n        rx, ry, rz = self.robot_pose[:3]\n        nearby = []\n        for obj in self.objects.values():\n            dist = ((obj.position[0] - rx)**2 +\n                   (obj.position[1] - ry)**2 +\n                   (obj.position[2] - rz)**2) ** 0.5\n            if dist <= radius:\n                nearby.append(obj)\n        return nearby\n'})}),"\n",(0,s.jsx)(n.h3,{id:"3-planning-and-decision-making",children:"3. Planning and Decision Making"}),"\n",(0,s.jsx)(n.p,{children:"The planning layer determines what actions to take:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from enum import Enum\nfrom typing import Optional\n\nclass RobotTask(Enum):\n    IDLE = "idle"\n    NAVIGATE = "navigate"\n    MANIPULATE = "manipulate"\n    EXPLORE = "explore"\n\nclass TaskPlanner:\n    """High-level task planning for the robot."""\n\n    def __init__(self, world_model: WorldModel):\n        self.world_model = world_model\n        self.current_task: Optional[RobotTask] = None\n\n    def plan_next_action(self, goal: str) -> RobotTask:\n        """Determine the next task based on the goal."""\n        # Simple goal parsing (in practice, use LLM or planner)\n        if "go to" in goal.lower():\n            return RobotTask.NAVIGATE\n        elif "pick up" in goal.lower():\n            return RobotTask.MANIPULATE\n        elif "explore" in goal.lower():\n            return RobotTask.EXPLORE\n        return RobotTask.IDLE\n'})}),"\n",(0,s.jsx)(n.h2,{id:"the-embodiment-hypothesis",children:"The Embodiment Hypothesis"}),"\n",(0,s.jsxs)(n.p,{children:["A key principle in Physical AI is the ",(0,s.jsx)(n.strong,{children:"embodiment hypothesis"}),": intelligence arises from the interaction between an agent's body and its environment. This contrasts with the view that intelligence is purely computational."]}),"\n",(0,s.jsxs)(n.admonition,{title:"Embodiment in Practice",type:"tip",children:[(0,s.jsx)(n.p,{children:"Consider how a human learns to catch a ball. This skill requires:"}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Visual processing of ball trajectory"}),"\n",(0,s.jsx)(n.li,{children:"Proprioception (sensing limb positions)"}),"\n",(0,s.jsx)(n.li,{children:"Motor coordination"}),"\n",(0,s.jsx)(n.li,{children:"Real-time adjustment based on feedback"}),"\n"]}),(0,s.jsx)(n.p,{children:"This integrated sensorimotor loop cannot be replicated by a disembodied AI."})]}),"\n",(0,s.jsx)(n.h2,{id:"why-humanoid-robots",children:"Why Humanoid Robots?"}),"\n",(0,s.jsx)(n.p,{children:"Humanoid robots are designed to operate in human environments:"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Feature"}),(0,s.jsx)(n.th,{children:"Advantage"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Bipedal locomotion"})}),(0,s.jsx)(n.td,{children:"Navigate stairs, step over obstacles"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Human-scale"})}),(0,s.jsx)(n.td,{children:"Use human tools and furniture"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Anthropomorphic hands"})}),(0,s.jsx)(n.td,{children:"Manipulate objects designed for humans"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Social presence"})}),(0,s.jsx)(n.td,{children:"Natural interaction with people"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Physical AI"})," bridges the gap between digital intelligence and physical action"]}),"\n",(0,s.jsx)(n.li,{children:"Core components include perception, world modeling, planning, and control"}),"\n",(0,s.jsxs)(n.li,{children:["The ",(0,s.jsx)(n.strong,{children:"embodiment hypothesis"})," suggests that true intelligence requires physical interaction"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Humanoid robots"})," are designed to operate seamlessly in human environments"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"whats-next",children:"What's Next?"}),"\n",(0,s.jsxs)(n.p,{children:["In the next chapter, we'll dive deep into ",(0,s.jsx)(n.strong,{children:"sensor systems"})," that enable robots to perceive their environment."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n","\n",(0,s.jsxs)(S,{title:"Concept Check: Physical AI Fundamentals",difficulty:"beginner",estimatedTime:10,type:"conceptual",children:[(0,s.jsx)(n.p,{children:"Answer the following questions:"}),(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"What are the three main differences between traditional AI and Physical AI?"}),"\n",(0,s.jsx)(n.li,{children:"Name the four core components of a Physical AI system."}),"\n",(0,s.jsx)(n.li,{children:"Explain the embodiment hypothesis in your own words."}),"\n"]})]}),"\n",(0,s.jsxs)(S,{title:"Code Analysis: Extending the World Model",difficulty:"intermediate",estimatedTime:20,type:"coding",hint:"You'll need to compare the current timestamp with the object's last_seen attribute.",children:[(0,s.jsxs)(n.p,{children:["Modify the ",(0,s.jsx)(n.code,{children:"WorldModel"})," class to include a method that removes objects not seen in the last 30 seconds."]}),(0,s.jsxs)(n.p,{children:["Then, extend the ",(0,s.jsx)(n.code,{children:"IMUReading"})," class to calculate the magnitude of acceleration using the formula:\n",(0,s.jsx)(n.code,{children:"magnitude = sqrt(ax\xb2 + ay\xb2 + az\xb2)"})]})]}),"\n",(0,s.jsxs)(S,{title:"System Design: Robot State Machine",difficulty:"advanced",estimatedTime:45,type:"hands-on",hint:"Consider what sensors are needed to detect when each state transition should occur. Think about edge cases like the object not being found or obstacles blocking the path.",children:[(0,s.jsx)(n.p,{children:"Design a state machine for a robot that must:"}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Search for an object"}),"\n",(0,s.jsx)(n.li,{children:"Navigate to the object"}),"\n",(0,s.jsx)(n.li,{children:"Pick up the object"}),"\n",(0,s.jsx)(n.li,{children:"Return to its starting position"}),"\n"]}),(0,s.jsx)(n.p,{children:"Your design should include:"}),(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"State diagram with all states and transitions"}),"\n",(0,s.jsx)(n.li,{children:"Sensor data required for each state transition"}),"\n",(0,s.jsx)(n.li,{children:"Error handling states (e.g., object not found, path blocked)"}),"\n",(0,s.jsx)(n.li,{children:"Pseudocode for the main control loop"}),"\n"]})]})]})}function L(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(W,{...e})}):W(e)}}}]);