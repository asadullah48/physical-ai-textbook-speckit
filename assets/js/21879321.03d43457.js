"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[928],{2762(e,i,o){o.r(i),o.d(i,{assets:()=>l,contentTitle:()=>a,default:()=>u,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-5-vla/index","title":"Module 5 Overview","description":"Vision-Language-Action Systems for Autonomous Behavior","source":"@site/docs/module-5-vla/index.mdx","sourceDirName":"module-5-vla","slug":"/module-5-vla/","permalink":"/physical-ai-textbook-speckit/docs/module-5-vla/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Module 5 Overview","description":"Vision-Language-Action Systems for Autonomous Behavior"},"sidebar":"tutorialSidebar","previous":{"title":"Module 4 Overview","permalink":"/physical-ai-textbook-speckit/docs/module-4-isaac/"},"next":{"title":"13-Week Course Breakdown","permalink":"/physical-ai-textbook-speckit/docs/instructor-guide/course-breakdown"}}');var n=o(4848),s=o(8453);const r={sidebar_position:1,title:"Module 5 Overview",description:"Vision-Language-Action Systems for Autonomous Behavior"},a="Module 5: Vision-Language-Action Systems",l={},c=[{value:"Topics Covered",id:"topics-covered",level:2},{value:"Chapters",id:"chapters",level:2},{value:"Prerequisites",id:"prerequisites",level:2}];function d(e){const i={em:"em",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,s.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(i.header,{children:(0,n.jsx)(i.h1,{id:"module-5-vision-language-action-systems",children:"Module 5: Vision-Language-Action Systems"})}),"\n",(0,n.jsx)(i.p,{children:"This module covers cutting-edge VLA systems that enable autonomous humanoid behavior."}),"\n",(0,n.jsx)(i.h2,{id:"topics-covered",children:"Topics Covered"}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsx)(i.li,{children:"Voice-to-action pipelines"}),"\n",(0,n.jsx)(i.li,{children:"LLM-based cognitive planning"}),"\n",(0,n.jsx)(i.li,{children:"Multi-modal perception"}),"\n",(0,n.jsx)(i.li,{children:"Capstone project: Autonomous humanoid behavior"}),"\n"]}),"\n",(0,n.jsx)(i.h2,{id:"chapters",children:"Chapters"}),"\n",(0,n.jsx)(i.p,{children:(0,n.jsx)(i.em,{children:"Chapters coming soon"})}),"\n",(0,n.jsx)(i.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,n.jsx)(i.p,{children:"Complete Module 4: NVIDIA Isaac Platform"})]})}function u(e={}){const{wrapper:i}={...(0,s.R)(),...e.components};return i?(0,n.jsx)(i,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},8453(e,i,o){o.d(i,{R:()=>r,x:()=>a});var t=o(6540);const n={},s=t.createContext(n);function r(e){const i=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function a(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:r(e.components),t.createElement(s.Provider,{value:i},e.children)}}}]);